version: '3.8'
services:
  cuda_app:
    build:
      context: .
      dockerfile: Dockerfile
    deploy:
      resources:
        reservations:
          devices:
          - capabilities: ["gpu"]
    volumes:
      - ./:/app
      - /home/zetaphor/LLMs/:/models
    environment:
      USE_MLOCK: "0"
      HOST: "0.0.0.0"
      CUDA_DOCKER_ARCH: "all"
      LLAMA_CUBLAS: "1"
    cap_add:
      - SYS_RESOURCE
    entrypoint: ["/bin/bash", "-c"]
    command: ["python3 /app/test2.py"]
